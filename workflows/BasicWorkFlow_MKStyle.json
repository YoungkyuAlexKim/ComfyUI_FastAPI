{
  "3": {
    "inputs": {
      "seed": 982018821834363,
      "steps": 30,
      "cfg": 3.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "ddim_uniform",
      "denoise": 1,
      "model": [
        "14",
        0
      ],
      "positive": [
        "23",
        0
      ],
      "negative": [
        "23",
        1
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "waiNSFWIllustrious_v13\\waiNSFWIllustrious_v150.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎìú"
    }
  },
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Îπà Ïû†Ïû¨ Ïù¥ÎØ∏ÏßÄ"
    }
  },
  "6": {
    "inputs": {
      "text": "CQArt, masterpiece, best quality, amazing quality, \n\n1girl, brown hair, short hair, armored_dress, \ncowboy_shot, tachi-e, \nown_hands_together, looking_at_viewer, happy, ",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Ìè¨ÏßÄÌã∞Î∏åÌîÑÎ°¨ÌîÑÌä∏_ÏãúÏä§ÌÖúÌîÑÎ°¨ÌîÑÌä∏"
    }
  },
  "7": {
    "inputs": {
      "text": "bad quality,worst quality,worst detail, signature, ",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "ÎÑ§Í±∞Ìã∞Î∏åÌîÑÎ°¨ÌîÑÌä∏"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "20",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE ÎîîÏΩîÎìú"
    }
  },
  "14": {
    "inputs": {
      "lora_name": "Characters\\Illustrious\\Aoba_Suzukaze.safetensors",
      "strength_model": 0,
      "strength_clip": 0,
      "prompt": "aoba-su, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower,\n\naoba-su, aoba-business, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower, formal jacket, shirt, white shirt, long sleeves, suit, ribbon, neck ribbon, skirt, socks, shoes, white socks, kneehighs,\n\naoba-su, aoba-business alt, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower, formal, shirt, white shirt, short sleeve, suit, ribbon, neck ribbon, skirt, socks, shoes, white socks, kneehighs,\n\naoba-su, aoba-casual, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, ribbon, hair ribbon, dress, blue dress, short sleeves, collarbone",
      "example": "notes",
      "model": [
        "42",
        0
      ],
      "clip": [
        "42",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss",
    "_meta": {
      "title": "Character Lora Loader üêç"
    }
  },
  "16": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "ÏóÖÏä§ÏºÄÏùº Î™®Îç∏ Î°úÎìú"
    }
  },
  "17": {
    "inputs": {
      "upscale_model": [
        "16",
        0
      ],
      "image": [
        "22",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìïú Ïù¥ÎØ∏ÏßÄ ÌôïÎåÄ"
    }
  },
  "18": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.75,
      "image": [
        "17",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Ïù¥ÎØ∏ÏßÄ ÌôïÎåÄ ÎπÑÏú®"
    }
  },
  "19": {
    "inputs": {
      "pixels": [
        "18",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Ïù∏ÏΩîÎìú"
    }
  },
  "20": {
    "inputs": {
      "seed": 0,
      "steps": 30,
      "cfg": 3.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "ddim_uniform",
      "denoise": 0.25,
      "model": [
        "14",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "19",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler(ÏóÖÏä§ÏºÄÏùºÎßÅ)"
    }
  },
  "22": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE ÎîîÏΩîÎìú"
    }
  },
  "23": {
    "inputs": {
      "strength": 0,
      "start_percent": 0,
      "end_percent": 0.33,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "control_net": [
        "25",
        0
      ],
      "image": [
        "28",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Ïª®Ìä∏Î°§ÎÑ∑ Ï†ÅÏö©"
    }
  },
  "25": {
    "inputs": {
      "control_net_name": "controlnetxlCNXL_xinsirScribbleAnime.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Ïª®Ìä∏Î°§ÎÑ∑ Î™®Îç∏ Î°úÎìú(Scribble)"
    }
  },
  "28": {
    "inputs": {
      "image": "50fdc1168ab6447da899d18209ca7aae.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Ïù¥ÎØ∏ÏßÄ Î°úÎìú(Ïª®Ìä∏Î°§ÎÑ∑Ïö©)"
    }
  },
  "36": {
    "inputs": {
      "model": [
        "14",
        0
      ],
      "clip": [
        "14",
        1
      ],
      "vae": [
        "4",
        2
      ],
      "positive": [
        "23",
        0
      ],
      "negative": [
        "23",
        1
      ]
    },
    "class_type": "ToBasicPipe",
    "_meta": {
      "title": "ToBasicPipe"
    }
  },
  "37": {
    "inputs": {
      "wildcard": "",
      "Select to add LoRA": "Select the LoRA to add to the text",
      "Select to add Wildcard": "Select the Wildcard to add to the text",
      "basic_pipe": [
        "36",
        0
      ],
      "bbox_detector": [
        "39",
        0
      ],
      "sam_model_opt": [
        "38",
        0
      ]
    },
    "class_type": "BasicPipeToDetailerPipe",
    "_meta": {
      "title": "BasicPipe -> DetailerPipe"
    }
  },
  "38": {
    "inputs": {
      "model_name": "sam_vit_l_0b3195.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "39": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "40": {
    "inputs": {
      "guide_size": 512,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 506160412331375,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.5,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "refiner_ratio": 0.2,
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "8",
        0
      ],
      "detailer_pipe": [
        "37",
        0
      ]
    },
    "class_type": "FaceDetailerPipe",
    "_meta": {
      "title": "ÏñºÍµ¥ ÎîîÌÖåÏùºÎü¨ (ÌååÏù¥ÌîÑ)"
    }
  },
  "41": {
    "inputs": {
      "images": [
        "40",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Ïù¥ÎØ∏ÏßÄ ÎØ∏Î¶¨Î≥¥Í∏∞(ÏµúÏ¢Ö)"
    }
  },
  "42": {
    "inputs": {
      "lora_name": "styles\\IllustriousAA\\CQArt_Illust.safetensors",
      "strength_model": 0.8,
      "strength_clip": 0.8,
      "prompt": "CQArt",
      "example": "notes",
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss",
    "_meta": {
      "title": "Style Lora Loader üêç"
    }
  }
}