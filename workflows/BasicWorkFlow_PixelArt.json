{
  "3": {
    "inputs": {
      "seed": 229327937008039,
      "steps": 30,
      "cfg": 3.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "ddim_uniform",
      "denoise": 1,
      "model": [
        "14",
        0
      ],
      "positive": [
        "23",
        0
      ],
      "negative": [
        "23",
        1
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "novaPixelsXL_v10\\novaPixelsXL_v10.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"
    }
  },
  "5": {
    "inputs": {
      "width": 800,
      "height": 800,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "ë¹ˆ ì ì¬ ì´ë¯¸ì§€"
    }
  },
  "6": {
    "inputs": {
      "text": "1girl, solo, standing, full_body, chibi, solid_oval_eyes, \naoba-su, aoba-business, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower, formal jacket, shirt, white shirt, long sleeves, suit, ribbon, neck ribbon, skirt, socks, shoes, white socks, kneehighs,\nsimple background, \nmasterpiece, best quality, amazing quality, pixel_art, ",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”© (Positive)"
    }
  },
  "7": {
    "inputs": {
      "text": "bad quality,worst quality,worst detail,sketch,censor, ",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”© (Negative)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "20",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE ë””ì½”ë“œ"
    }
  },
  "14": {
    "inputs": {
      "lora_name": "Characters\\Illustrious\\Aoba_Suzukaze.safetensors",
      "strength_model": 0,
      "strength_clip": 0,
      "prompt": "aoba-su, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower,\n\naoba-su, aoba-business, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower, formal jacket, shirt, white shirt, long sleeves, suit, ribbon, neck ribbon, skirt, socks, shoes, white socks, kneehighs,\n\naoba-su, aoba-business alt, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, hair ornament, flower, hair flower, formal, shirt, white shirt, short sleeve, suit, ribbon, neck ribbon, skirt, socks, shoes, white socks, kneehighs,\n\naoba-su, aoba-casual, 1girl, purple eyes, twintails, purple hair, bangs, long hair, very long hair, ribbon, hair ribbon, dress, blue dress, short sleeves, collarbone",
      "example": "notes",
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss",
    "_meta": {
      "title": "Lora Loader ğŸ"
    }
  },
  "16": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "ì—…ìŠ¤ì¼€ì¼ ëª¨ë¸ ë¡œë“œ"
    }
  },
  "17": {
    "inputs": {
      "upscale_model": [
        "16",
        0
      ],
      "image": [
        "22",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í™•ëŒ€"
    }
  },
  "18": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.75,
      "image": [
        "17",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "ì´ë¯¸ì§€ í™•ëŒ€ ë¹„ìœ¨"
    }
  },
  "19": {
    "inputs": {
      "pixels": [
        "18",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE ì¸ì½”ë“œ"
    }
  },
  "20": {
    "inputs": {
      "seed": 0,
      "steps": 30,
      "cfg": 3.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "ddim_uniform",
      "denoise": 0.4,
      "model": [
        "14",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "19",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "22": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE ë””ì½”ë“œ"
    }
  },
  "23": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 0.33,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "control_net": [
        "25",
        0
      ],
      "image": [
        "28",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "ì»¨íŠ¸ë¡¤ë„· ì ìš©"
    }
  },
  "25": {
    "inputs": {
      "control_net_name": "controlnetxlCNXL_xinsirScribbleAnime.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "ì»¨íŠ¸ë¡¤ë„· ëª¨ë¸ ë¡œë“œ"
    }
  },
  "26": {
    "inputs": {
      "measurement": "percentage",
      "width": 25,
      "height": 25,
      "fit": "crop",
      "method": "nearest-exact",
      "image": [
        "8",
        0
      ]
    },
    "class_type": "Image Resize (rgthree)",
    "_meta": {
      "title": "Image Resize (rgthree)"
    }
  },
  "28": {
    "inputs": {
      "image": "scribble0.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "ì´ë¯¸ì§€ ë¡œë“œ"
    }
  },
  "29": {
    "inputs": {
      "images": [
        "26",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "FinalImage(Preview)"
    }
  }
}